import openai
import tweepy
import os
import re
import json

from tweet_score import find_score

openai.api_key = "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"

consumer_key = "MSd2CjX2z3D7y8mTTPSQg3CsV"
consumer_secret = "5CFBQgrgWN2Fk9dr9vpYNyyHFTc8J1aiirtqnBPCiPseSgi0eJ"
access_token = "1304455384304762880-Ill9A1L1zXgurjH1Ap4bxLIAAW7Ds2"
access_token_secret = "5Bz93vrdl4tGjhe7LnaRRPPx6YaX2qLDEt3CaFImCkJLU"

# Authenticate to Twitter
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
twitter_api = tweepy.API(auth, wait_on_rate_limit=True)

# loading the news.json dataset

# dtset = pd.read_json(os.path.join(os.path.dirname(__file__), "./data/news.json"))
# queries = dtset.loc[:, "title"]
with open(os.path.join(os.path.dirname(__file__), "./data/news.json")) as f:
    dtset = json.load(f)


# looping through each article
final_data = []
pattern = re.compile(r"\d+\.\s*(.*)")  # matches one or more digits followed by a period, optionally followed by
# whitespace (the \s*), and then captures any character except a newline in a group (the (.*)).

for ix in range(3):
    prompt = """Give 2 most relevant topics based on
     following news headline: {}""".format(
        dtset[ix]["title"]
    )
    response = openai.Completion.create(engine="text-davinci-003", prompt=prompt, max_tokens=256)

    # preprocessing responses generated by davinci model

    query_response = response["choices"][0]["text"]
    # print(query_response)

    query_array = re.findall(pattern, query_response.strip())
    # print(query_array)

    query_string = " OR ".join(f'"{term}"' for term in query_array)

    query_string_noRetweets = f"{query_string} -filter:retweets"

    # print(query_string_noRetweets)
    # query_expression = ast.parse(query_string, mode="eval").body
    # print(query_expression)

    # recent_tweets = twitter_api.search_tweets(q=query_string_noRetweets, count=3)
    recent_tweets = tweepy.Cursor(
        twitter_api.search_tweets, q=query_string_noRetweets, tweet_mode="extended", include_entities=True
    ).items(3)
    # print(recent_tweets)

    tweet_json_data = {"title_of_article": dtset[ix]["title"], "search_query": query_string, "tweets": []}

    for tweet in recent_tweets:
        image_url = []
        video_info = {}
        url_of_tweet = "https://twitter.com/twitter/statuses/" + tweet.id_str
        if "media" in tweet.entities:
            for image in tweet.entities["media"]:
                image_url.append(image["media_url"])
        if "extended_entities" in tweet._json:
            video_info = tweet.extended_entities["media"][0].get("video_info")
        if tweet.full_text and url_of_tweet:
            user = {
                "name": tweet.user.name,
                "location": tweet.user.location,
                "description": tweet.user.description,
                "friends": tweet.user.friends_count,
                "followers": tweet.user.followers_count,
            }
            retweets = tweet.retweet_count
            favourites = tweet.favorite_count
            created_at = tweet.created_at
            hashtags = tweet.entities["hashtags"]
            score = find_score(
                user["description"],
                user["followers"],
                created_at,
                tweet.full_text,
                favourites,
                retweets,
                hashtags,
                dtset[ix]["title"],
                dtset[ix]["text"],
                dtset[ix]["date"],
            )
            tweet_json_data["tweets"].append(
                {
                    "tweet_id": tweet.id,
                    "tweet_created_at": str(created_at),
                    "tweet_text": tweet.full_text,
                    "hashtags": hashtags,
                    "tweet_url": url_of_tweet,
                    "tweet_images_url": image_url,
                    "tweet_video_info": video_info,
                    "user_info": user,
                    "tweet_retweetcount": retweets,
                    "tweet_likecount": favourites,
                    "tweet_score": score,
                }
            )

    final_data.append(tweet_json_data)

# writing the tweets into a json file
with open("./data/tweets1.json", "w") as json_file:
    json.dump(final_data, json_file)
