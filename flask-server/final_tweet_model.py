import openai
import tweepy
import pandas as pd
import json
import re

openai.api_key = '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'

consumer_key = 'MSd2CjX2z3D7y8mTTPSQg3CsV'
consumer_secret = '5CFBQgrgWN2Fk9dr9vpYNyyHFTc8J1aiirtqnBPCiPseSgi0eJ'
access_token = '1304455384304762880-Ill9A1L1zXgurjH1Ap4bxLIAAW7Ds2'
access_token_secret = '5Bz93vrdl4tGjhe7LnaRRPPx6YaX2qLDEt3CaFImCkJLU'
# Authenticate to Twitter
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)

# loading the news.json dataset
dtset = pd.read_json("C:/Users/jeetk/OneDrive/Desktop/news.json")
queries = dtset.loc[:,"title"]

# looping through each article
final_data=[]
for ix in range(5):
    prompt = "Give me only top 2 most relevant topics based on following news headline strictly as a string seperated by comma: {}".format(queries[ix])
    response = openai.Completion.create(engine="text-davinci-003",prompt=prompt,max_tokens=256)

    # preprocessing responses generated by davinci model
    t = response["choices"][0]["text"]
    str(t)
    b = t.strip()
    c = b.strip('\n')
    d = c.strip('\n')
    e = d.replace('"','')
    x = t.split(",")
    for a in range(len(x)):
        str(x[a])

    q1 = x[0].replace('"','')
    q2 = x[1].replace('"','')

    print(q1)
    print(q2)

    final_temp_data=[]
    json_data=[]
    image_url =[]
    query1 = f'{q1} -filter:retweets' 
    query2 = f'{q2} -filter:retweets'
    recent_tweets = api.search_tweets(q=query1 and query2, count=3)
    for tweet in recent_tweets:
        # print(tweet.text)
        url_of_tweet = "https://twitter.com/twitter/statuses/"+str(tweet.id)
        if 'media' in tweet.entities:
            for image in  tweet.entities['media']:
                image_url = image['media_url']
        if tweet.text and url_of_tweet:
            v1 = int(tweet.retweet_count)
            v2 = int(tweet.favorite_count)
            score = v1*(0.6) + v2*(0.4)
            json_data.append({"search_queries_tweepy":q1+' '+q2,"tweet_content":f'{tweet.text}',"tweet_url":f'{url_of_tweet}',"tweet_retweetcount":f'{tweet.retweet_count}',"tweet_likecount":f'{tweet.favorite_count}',"tweet_score":score})
    final_temp_data.append({"title_of_article":queries[ix],"tweets":json_data})
    final_data.append([final_temp_data])

# writing the tweets into a json file
with open('tweets.json', 'w') as json_file:
    json.dump(final_data, json_file)

